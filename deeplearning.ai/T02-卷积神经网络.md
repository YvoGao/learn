## 计算机视觉基础

- 图片分类
- 图片识别
- 风格迁移



*图片有RGB三个颜色通道*

### 卷积

input：6\*6到 kenel:3/*3   output：4\*4——》input和kenel对位相乘之和

垂直边缘检测的卷积核

[1,0,-1

1,0,-1

1,0,-1]

水平边缘检测的卷积核

[1,1,1

0,0,0

-1,-1,-1]



常用的卷积核(f\*f\*f3)

sobel filter

[1,0,-1

2,0,-2

1,0,-1]



schorr filter(f\*f)

[3,0,-3

10,0-10

3,0,-3]

### 三种常用的卷积

1.full  mode

<img src="https://img-blog.csdn.net/20180515205400757" alt="img" style="zoom:33%;" />

橙色部分为image, 蓝色部分为filter。full模式的意思是，从filter和image刚相交开始做卷积，白色部分为填0。filter的运动范围如图所示。

2.same mode

<img src="https://img-blog.csdn.net/20180515205624201" alt="img" style="zoom:33%;" />

当filter的中心(K)与image的边角重合时，开始做卷积运算，可见filter的运动范围比full模式小了一圈。注意：这里的same还有一个意思，卷积之后输出的feature map尺寸保持不变(相对于输入图片)。当然，same模式不代表完全输入输出尺寸一样，也跟卷积核的步长有关系。same模式也是最常见的模式，因为这种模式可以在前向传播的过程中让特征图的大小保持不变，调参师不需要精准计算其尺寸变化(因为尺寸根本就没变化)。

3.valid

<img src="https://img-blog.csdn.net/20180515205946981" alt="img" style="zoom:33%;" />

当filter全部在image里面的时候，进行卷积运算，可见filter的移动范围较same更小了。

### Padding(p)

图像外部填充，或者使用valid 和same卷积



### 卷积步长(s)

每一次移动的距离

input(n\*n\*n3)

output{m\*m\*m3}

m=$$ \lfloor(n+2p-f)/s\rfloor+1$$

m3 = 卷积核的个数



### 池化层

过滤器f，步长s，很少用padding

- 最大池化：选取f*f区域最大的值——往往效果好
- 平均池化：选取f*f区域的平均值

### 全连接层

将所有的数据展开成二维N*1的结构

### 残差网络

每两层进行一次跳跃

### inception

把所有方法都用到每一层中，通过训练选取合适的组合。 ——》计算代价太大



## 目标检测

### 目标定位

锚框

一般来说，左上角为（0，0），输出为

$[P_c, b_x, b_y, b_h, b_w, c_1, c_2, c_3,]^T$

> $P_c$表示为一个物体的概率，0时后面参数无意义
>
> $ b_x, b_y, b_h, b_w,$表示框的左上角顶点x，y坐标和宽和高
>
> $c_1, c_2, c_3$中只有一处为1表示为，最有可能是这个类

$P_c=1, Loss=(\hat{y_1}-y_1)^2+(\hat{y_2}-y_2)^2....+(\hat{y_n}-y_n)^2$

$P_c=0,Loss=(\hat{y_1}-y_1)^2$



### 目标检测

- 使用一个窗口滑动检测，对每一个窗口进行目标检测——》代价大

- 在卷积层上应用这个方法：对一张图片卷积，一次性得到所有预测值

- Bounding box：yolo方法，把图像分成3*3小格，对每一格使用卷积的方法，找到物体的中点

  >$ b_x, b_y, b_h, b_w,$是相对于格子的比例

- Anchor boxs：多个形状的anchor box分配到一个格子里，为了处理多个对象在一个格子里，（自动选择，k-mean聚类）

- R-CNN：图像分割，在一些区域色块使用滑动窗格的方法，缺点太慢了

- Fast-R-CNN：图像分割，使用卷积的滑动实现方法

- Faster-R-CNN：使用卷积实现图像分割得到候选区域，然后进行滑动卷积实现，但是还是比yolo满（作者认为）

### 一些评价指标

- 交并法(IOU)：计算预测框和实际框的交集大小，一般>=0.5为正确的（人为定的）
- 非极大值抑制：对和最大$P_c$值的框相交的宽进行删除，分类有几种就抑制几次

## 人脸识别

one-hot方法：学会比对两个图片的相似性

Siamese network网络：相同的图片差距值小

Triplet损失：源于3张图片（A，P，N）$Loss=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+\alpha\leq 0)$即$d(A,P)+\alpha \leq d (A,N)$，尽可能选取$d(A,N)和d(A,P)$来训练模型

面部验证和二分类方法：成对的图片输入，判断结果是否相似，转化为二分类问题

## 风格迁移

深度卷积神经网络

- 代价函数：$Loss = \alpha J_{content}(C,G)+\beta J_{style}(S,G)$

- - 内容代价函数 $J_{content}(C,G)=1/2||a^{[l](c)}-a^{[l](G)}||^2$
  
  - 风格代价函数$J_{style}(S,G)=\beta\sum_{k}\sum_{k'}(G_{kk'}^{[l][S]}-G_{kk'}^{[l][G]})$ 
  
    $G_{kk'}^{[l][s]}=\sum_{i=1}^{n_{H}[l]}\sum_{j=1}^{n_{W}[l]}a_{ijk}a_{ijk'}$相当于一个斜方差的概念，k通道和k'通道如果相似则数会变大 

## 一维到三维的推广

filter卷积核符合输入的样子，即：1D-->1D， 3D-->3D。

同样由filter数目决定最后一层维度
