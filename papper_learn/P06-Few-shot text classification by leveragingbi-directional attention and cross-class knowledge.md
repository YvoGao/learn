# Few-shot text classification by leveragingbi-directional attention and cross-class knowledge

这篇文章研究了基于度量的元学习框架下的小样本文本分类问题。虽然查询和支持实例的表示是分类的关键，但已有的研究在文本编码阶段**独立**处理它们。为了更好地描述分类特征，我们提出利用分类特征与自适应的**双向注意机制**的交互作用。此外，与以前独立编码各种类的方法不同，我们利用底层的**跨类知识**进行分类。为此，我们通过**引入较大的边际损失**来设想学习目标，期望在拉大类间距离的同时缩短类内距离。

## 双向注意力

这部分将查询实例和支持集联系起来，具体分成四步进行。

- 逐字相似度矩阵：通过多层感知机的方法来计算查询实例和支持实例的相似度矩阵。

  $$C_{ij}^k=v_1^T[Q_{i:}:S_{j:}^k:Q_{i:}\circ S_{j:}^k]$$

  其中，:是连接操作，$Q_i$：是Q的第i行，$S^k_j$：是$S^k$的第j行，◦是逐元素乘法运算，$v_1 \in \R^{6d_h} $是可训练参数。$C^k$包含查询Q和第k个支持实例$S^k$之间的关注信息。

- 支持到查询注意力：表示查询中的哪些词与支持实例中的词相关。

  $$\alpha_t^k = softmax(C_{:t}^k)\in \R^T$$

  其中$C^k_{:t}$是$C^k$的第t列，因此，支持实例中第t个单词的查询感知向量表示为$\hat S_{t:}^k=\alpha_t^{kT}Q$。

- 查询到支持注意力：表示支持实例中的哪些词与查询中的词相关。

  $$\beta_t^k=softmax(C_{t:}^k)\in\R^T$$

  其中$C_{t:}^k$：是$C^k$的第t行。当第k个支持实例与查询实例相关时，我们获得支持实例中最重要的词相对于查询的加权和$\hat Q_{t:}^k=\beta_t^{kT}S^K$。

- 特征融合：每个查询和支持实例的原始表示和参与表示之间的交互进行建模。

  对于查询实例表示为$\Q = g([Q:\hat Q:Q \circ \hat Q]W_1)$

  其中$\hat Q = \frac 1 K\sum_{k=1}^K\hat Q^k, W_! \in \R^{6d_h\times d_s}$，g是ReLU函数

  同样的，支持实例表示$\S^k = g([S^k:\hat S^k:S^k\circ \hat S^k]W_1)$

  $W_1$是共用的，统一的映射函数来降低支持实例和查询实例的表示的维度。统一的映射函数保证将实例编码到相同的向量空间。

## 跨类知识

本文是如何做到跨类知识迁移的呢？

![image-20220120220034121](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220120220034121.png)

